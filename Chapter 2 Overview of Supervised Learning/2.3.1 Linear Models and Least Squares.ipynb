{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear regression is a straightforward approach for predicting a quantitative reponse $Y$ on the basis of a single predictor variable $X$. It assumes that there is approximately a linear relationship between $X$ and $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y \\approx \\beta_0 + \\beta_1 X$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta_0$ and $\\beta_1$ are two unknown constants that represent the intercept and slope terms in the linear model respectively. The intercept is the expected value of $Y$ when $X=0$. The slope is the average increase in $Y$ associated with a one-unit increase in $X$. They are known as the model coefficients or parameters. Through training data we can obtain estimates of the coefficients that can be used to make predictions of $Y$ on the basis of $X=x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} =  \\hat{\\beta_0} + \\hat{\\beta_1} x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)$ represent $n$ observation pairs, each of which consists of a measurement of $X$ and a measurement of $Y$. We want to find an intercept $\\hat{\\beta_0}$ and a slope $\\hat{\\beta_1}$ such that the resulting line is as close as possible to the $n$ observation points. The most common approach for obtaining the optimal coefficients is to minimize the least squares criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\hat{y_i}= \\hat{\\beta_0} + \\hat{\\beta_1} x_i$ be the prediction for $Y$ based on the $i$th value of $X$. Then $e_i = y_i - \\hat{y_i}$ represents the $i$th residual, i.e. the difference between the $i$th observed response value and the $i$th predicted response value by our linear model. We define the residual sum of squares (RSS) as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "RSS &= e_1^2 + e_2^2 + \\dots + e_n^2 \\\\\n",
    "&= (y_1 - \\hat{y_1})^2 + (y_2 - \\hat{y_2})^2 + \\dots + (y_n - \\hat{y_n})^2\\\\\n",
    "&= (y_1 - \\hat{\\beta_0} + \\hat{\\beta_1} x_1)^2 + (y_2 -  \\hat{\\beta_0} + \\hat{\\beta_1} x_2)^2 + \\dots + (y_n -  \\hat{\\beta_0} + \\hat{\\beta_1} x_n)^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares approach selects $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ to minimize RSS. These can be shown to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta_1} = \\dfrac{\\sum^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum^n_{i=1}(x_i-\\bar{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\bar{y} \\equiv \\frac{1}{n} \\sum^n_{i=1}y_i$ and $\\bar{x} \\equiv \\frac{1}{n} \\sum^n_{i=1} x_i$ are the sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the accuracy of the coefficient estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the true relationship between $X$ and $Y$ takes the form $Y=f(X) + \\epsilon$ for some unknown function $f$, where $\\epsilon$ is a mean-zero random error term. If $f$ is to be approximated by a linear function, then we can write this relationship as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y = \\beta_0 + \\beta_1 X + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error term $\\epsilon$ is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that cause variation in Y , and there may be measurement error. We typically assume that the error term is independent of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of a linear regression fit is typically assessed using two related quantities: the residual standard error (RSE) and the $R^2$ statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual standard error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSE is an estimate of the standard deviation of $\\epsilon$. Roughly speaking, it is the average amount that the response\n",
    "will deviate from the true regression line. It is considered a measure of the lack of fit of the model to\n",
    "the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSE=\\sqrt{\\dfrac{1}{n-2}RSS}=\\sqrt{\\dfrac{1}{n-2}\\sum^n_{i=1}(y_i-\\hat{y_i})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^2=\\dfrac{TSS-RSS}{TSS}=1-\\dfrac{RSS}{TSS}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $TSS=\\sum(y_i-\\bar{y})^2$. TSS measures the total variance in the response $Y$ , and can be thought of as the amount of variability inherent in the response before the regression is performed. In contrast, RSS measures the amount of variability that is left unexplained after performing the regression. Hence, TSS âˆ’ RSS measures the amount of variability in the response that is explained (or removed) by performing the regression, and $R^2$ measures the proportion of variability in $Y$ that can be explained using $X$. It can be thought of as a measure of the linear relationship between $X$ and $Y$, similar to correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r=Cor(X,Y)=\\dfrac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple linear regression we have that $r^2=R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each predictor is given a separate slope coefficient. We interpret $\\beta_p$ as the average effect on $Y$ of a one unit increase in $X_p$ , holding all other predictors fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $p$ is the number of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_0:\\beta_1=\\beta_2=\\dots=\\beta_p=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_1: \\text{at least one of } \\beta_j \\text{ is non-zero.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F=\\dfrac{(TSS-RSS)/p}{TSS/(n-p-1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the linear model assumptions are correct then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E\\{TSS/(n-p-1)\\} = \\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " provided $H_0$ is true then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E\\{(TSS-RSS)/p\\} = \\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence when there is no relationship between the response and the predictors the F-statistic takes on a value close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
